# 🌱 MSEED: Multidimensional Safety Evaluation and Enhancement Dataset for LLMs

## 🧩  Overview

Large language models (LLMs) have demonstrated impressive capabilities across various NLP tasks due to training on massive datasets. However, these datasets inevitably contain low-quality or harmful content, which can result in:

- ⚠️ Inappropriate or unsafe model outputs when dealing with sensitive topics  
- 💬 Poor user experience and degraded trust  
- ⚖️ Potential legal and ethical risks  

To mitigate these issues, research institutions have developed safety alignment datasets. Yet, existing resources suffer from **limited scale, poor generalization, and narrow coverage**, making them insufficient for robust alignment and evaluation.

### ✅ Why MSEED?

**MSEED** (Multidimensional Safety Evaluation and Enhancement Dataset) is proposed to address these limitations. It is designed to:

- 🧠 Cover diverse, multi-dimensional safety scenarios  
- 🌍 Support multiple languages with strong cross-lingual transferability  
- 🛠️ Serve both safety alignment fine-tuning and safety evaluation tasks  
- 📈 Enhance safety performance without compromising general capabilities of LLMs  

---

### 📌 分类标准 Categories

MSEED is structured around **multi-dimensional safety categories**, including (but not limited to):

| 分类维度         | 示例主题                                |
|------------------|-----------------------------------------|
| Harmful Outputs   | Violence, self-harm, hate speech        |
| Misinformation    | Health misinformation, fake news        |
| Privacy Risks     | Personal data leakage, sensitive info   |
| Ethical Misconduct| Unethical advice, manipulation tactics  |
| Legal Risk        | Illegal activities, copyright violation |
| Cultural Sensitivity | Biases, stereotypes, regional taboos |

Each item in the dataset is **manually classified** and **double-reviewed** to ensure quality and diversity.

---

### 📁 数据集目录 Dataset Structure

